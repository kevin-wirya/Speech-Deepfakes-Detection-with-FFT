\section{Introduction}

Recent advances in speech synthesis and voice conversion have enabled machines to generate highly realistic human speech. Modern text-to-speech and voice cloning systems are capable of producing audio that is increasingly difficult to distinguish from genuine human recordings. A study reports that human participants were only able to accurately distinguish real from AI-generated voices with an accuracy of 
70.4\%. This leads to a serious risks that can be posed by speech deepfakes in areas such as biometric authentication and digital forensics. Reports indicate that voice-based fraud has increased significantly in recent years, with financial losses reaching billions of dollars globally. Deepfake-related losses have already reached \$1.56 billion, with over \$1 billion occurring in 2025 alone.

While deep learning models have achieved impressive performance in generating natural-sounding speech, detecting such synthetic audio remains a challenging task. Many existing detection methods rely heavily on large neural networks trained on specific datasets. Although effective, these approaches often lack interpretability and tend to degrade when exposed to unseen deepfake generation methods. Moreover, purely data-driven models can be computationally expensive and difficult to analyze, making them less suitable and reliable at present time.

Speech signals, however, are fundamentally mathematical objects. A digital audio signal can be represented as a finite sequence of samples, which naturally forms a vector in a high-dimensional space. Transforming this signal into the frequency domain using the Fast Fourier Transform (FFT) reveals its spectral structure, including energy distribution and phase behavior. These properties are governed by well-established principles of linear algebra and geometry, such as vector spaces, orthonormal bases, inner products, and unitary transformations. Importantly, while deepfake speech models often reproduce spectral magnitudes accurately, subtle geometric inconsistencies in phase relationships and spectral structure may persist.

Motivated by this observation, this paper proposes a speech deepfake detection approach grounded in the linear algebraic and geometric foundations of the FFT. The proposed method aims to distinguish genuine and synthetic speech through interpretable mathematical measures. The development of this approach is supported by core theories from complex linear algebra and geometric signal analysis, which together provide a principled framework for understanding and detecting anomalies in synthetic speech. hello hi
