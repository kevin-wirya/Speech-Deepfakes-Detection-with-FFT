\section{Introduction}

Recent advances in speech synthesis and voice conversion have enabled machines to generate highly realistic human speech. Modern text-to-speech and voice cloning systems are capable of producing audio that is increasingly difficult to distinguish from genuine human recordings. A study reports that human participants were only able to accurately distinguish real from AI-generated voices with an accuracy of 
70.4\%. This leads to a serious risks that can be posed by speech deepfakes in areas such as biometric authentication and digital forensics. Reports indicate that voice-based fraud has increased significantly in recent years, with financial losses reaching billions of dollars globally. Deepfake-related losses have already reached \$1.56 billion, with over \$1 billion occurring in 2025 alone.

While deep learning models have achieved impressive performance in generating natural-sounding speech, detecting such synthetic audio remains a challenging task. Many existing detection methods rely heavily on large neural networks trained on specific datasets. Although effective, these approaches often lack interpretability and tend to degrade when exposed to unseen deepfake generation methods. Moreover, purely data-driven models can be computationally expensive and difficult to analyze, making them less suitable and reliable at present time.

Speech signals, however, are fundamentally mathematical objects. A digital audio signal can be represented as a finite sequence of samples, which naturally forms a vector in a high-dimensional space. Transforming this signal into the frequency domain using the Fast Fourier Transform (FFT) reveals its spectral structure, including phase behavior. These properties are governed by well-established principles of linear algebra and geometry, such as vector spaces, orthonormal bases, inner or dot products, and unitary transformations. From a linear algebra perspective, the FFT can be interpreted as a linear transformation that maps a time-domain signal into a complex frequency-domain vector. While synthetic speech models often reproduce spectral magnitudes effectively, differences in phase behavior may still arise.

Motivated by this observation, this paper proposes a speech deepfake detection approach grounded in the linear algebraic and geometric interpretation of the FFT. Rather than relying on large data-driven models, the proposed method focuses on analyzing basic algebraic properties of complex spectral representations. The approach aims to provide an interpretable demonstration of how concepts from complex linear algebra and geometry can be applied to distinguish genuine and synthetic speech signals.
